{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook we used for using the same network architecture to predict the correct paragraph.(we didn't use this approach in the end due to performance issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import timeline\n",
    "import json\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "filename = \"./record/train.tfrecords\"\n",
    "\n",
    "epoch = 1000\n",
    "batch = 32\n",
    "classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding = np.load(\"embedding.npy\").astype(\"float32\")\n",
    "with open(\"word_dict.json\",\"r\") as f:\n",
    "    word_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = np.load(\"c.npy\")\n",
    "c_char = np.load(\"c_char.npy\")\n",
    "q = np.load(\"q.npy\")\n",
    "q_char = np.load(\"q_char.npy\")\n",
    "dlab = np.load(\"lab.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unknown_detection(token_list):\n",
    "    new_list = []\n",
    "    for token in token_list:\n",
    "        if token in word_dict:\n",
    "            new_list.append(token)\n",
    "        else:\n",
    "            new_list.append(\"<UNK>\")\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_indices = np.arange(len(c))\n",
    "def dev_batch(batch=64):\n",
    "    while True:\n",
    "        np.random.shuffle(train_indices)\n",
    "        for i in range(int(math.ceil(len(c)/batch))):\n",
    "            start_index = (i*batch)%len(c)\n",
    "            idx = train_indices[start_index:start_index+batch]\n",
    "            c_b = c[idx]\n",
    "            c_char_b = c_char[idx]\n",
    "            q_b = q[idx]\n",
    "            q_char_b = q_char[idx]\n",
    "            dlab_b = dlab[idx]\n",
    "            yield c_b, c_char_b, q_b, q_char_b, dlab_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_dp(set1,set2):\n",
    "    assert len(set1) == len(set2)\n",
    "    max1 = 0\n",
    "    maxi1 = 0\n",
    "    maxpair = None\n",
    "    maxp = 0\n",
    "    for i in range(len(set1)):\n",
    "        if set1[i]>max1:\n",
    "            max1 = set1[i]\n",
    "            maxi1 = i\n",
    "        if max1 * set2[i] > maxp:\n",
    "            maxp = max1 * set2[i]\n",
    "            maxpair = [maxi1,i]\n",
    "    assert maxpair[0] <= maxpair[1]\n",
    "    return maxpair,maxp\n",
    "\n",
    "def f_train(pred_s, pred_e, true_s, true_e, context):\n",
    "    # computes average f_measure for a batch\n",
    "    f_sum = 0\n",
    "    l = len(pred_s)\n",
    "    for i in range(l):\n",
    "        #s_i = np.argmax(pred_s[i])\n",
    "        #e_i = np.argmax(pred_e[i])\n",
    "        \n",
    "        [s_i,e_i],_ = prob_dp(pred_s[i],pred_e[i])\n",
    "        if e_i < s_i:\n",
    "            continue\n",
    "        TP, FN, FP = 0, 0, 0\n",
    "        guess = context[i][s_i:e_i+1]\n",
    "        true = context[i][true_s[i]:true_e[i]+1]\n",
    "        for token in guess:\n",
    "            if token in true:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        for token in true:\n",
    "            if token not in guess:\n",
    "                FN += 1\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        f = 2*precision*recall/(precision+recall+1e-8)\n",
    "        f_sum += f\n",
    "    return f_sum/l\n",
    "\n",
    "def f_dev(pred_s, pred_e, a, context):\n",
    "    # computes average f_measure for a batch\n",
    "    f_sum = 0\n",
    "    l = len(pred_s)\n",
    "    for i in range(l):\n",
    "        #s_i = np.argmax(pred_s[i])\n",
    "        #e_i = np.argmax(pred_e[i])\n",
    "        \n",
    "        [s_i,e_i],_ = prob_dp(pred_s[i],pred_e[i])\n",
    "        if e_i < s_i:\n",
    "            continue\n",
    "        TP, FN, FP = 0, 0, 0\n",
    "        guess = context[i][s_i:e_i+1]\n",
    "        true = [word_dict[t] for t in unknown_detection(a[i])]\n",
    "        for token in guess:\n",
    "            if token in true:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        for token in true:\n",
    "            if token not in guess:\n",
    "                FN += 1\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        f = 2*precision*recall/(precision+recall+1e-8)\n",
    "        f_sum += f\n",
    "    return f_sum/l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer_softmax(logits,axis=-1):\n",
    "    #return tf.keras.backend.softmax(logits,axis=axis)\n",
    "    #return tf.nn.softmax(logits,axis=axis)\n",
    "    return tf.keras.layers.Softmax(axis=axis)(logits)\n",
    "    return tf.exp(logits)/tf.reduce_sum(tf.exp(logits),axis = axis,keepdims = True)\n",
    "\n",
    "def embedding_encoder_block(scope, inputs):\n",
    "    with tf.variable_scope(scope,reuse=tf.AUTO_REUSE):\n",
    "        # first encode input with position info\n",
    "        pos_encoded = position_encoding(inputs)\n",
    "        # project input to dimension 128\n",
    "        residual1 = tf.layers.separable_conv1d(pos_encoded, 128, 1, padding=\"same\",activation=tf.nn.relu)\n",
    "        \n",
    "        #convolution block\n",
    "        norm1 = tf.contrib.layers.layer_norm(residual1)\n",
    "        norm1 = tf.nn.dropout(norm1, 1-dp)\n",
    "        conv1 = tf.layers.separable_conv1d(norm1, 128, 7, padding=\"same\",activation=tf.nn.relu)\n",
    "        conv1 = tf.nn.dropout(conv1, 1-dp)\n",
    "        residual2 = tf.add(residual1, conv1)\n",
    "        \n",
    "        norm2 = tf.contrib.layers.layer_norm(residual2)\n",
    "        norm2 = tf.nn.dropout(norm2, 1-dp)\n",
    "        conv2 = tf.layers.separable_conv1d(norm2, 128, 7, padding=\"same\",activation=tf.nn.relu)\n",
    "        conv2 = tf.nn.dropout(conv2, 1-dp)\n",
    "        residual3 = tf.add(residual2, conv2)\n",
    "        \n",
    "        norm3 = tf.contrib.layers.layer_norm(residual3)\n",
    "        norm3 = tf.nn.dropout(norm3, 1-dp)\n",
    "        conv3 = tf.layers.separable_conv1d(norm3, 128, 7, padding=\"same\",activation=tf.nn.relu)\n",
    "        conv3 = tf.nn.dropout(conv3, 1-dp)\n",
    "        residual4 = tf.add(residual3, conv3)\n",
    "        \n",
    "        norm4 = tf.contrib.layers.layer_norm(residual4)\n",
    "        norm4 = tf.nn.dropout(norm4, 1-dp)\n",
    "        conv4 = tf.layers.separable_conv1d(norm4, 128, 7, padding=\"same\",activation=tf.nn.relu)\n",
    "        conv4 = tf.nn.dropout(conv4, 1-dp)\n",
    "        residual5 = tf.add(residual4, conv4)\n",
    "\n",
    "        # self-attention block\n",
    "        norm4 = tf.contrib.layers.layer_norm(residual5)\n",
    "        attention = tf.matmul(norm4, norm4, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(norm4)[-1], dtype=tf.float32)\n",
    "        scaled = tf.divide(attention, tf.sqrt(dk))\n",
    "        attention = layer_softmax(scaled, axis=-1)\n",
    "        #attention = tf.nn.softmax(scaled, axis=-1)\n",
    "        attention_out = tf.matmul(attention, norm4)\n",
    "        residual6 = tf.add(residual5, attention_out)\n",
    "        \n",
    "        # feedforwoad layer\n",
    "        norm5 = tf.contrib.layers.layer_norm(residual6)\n",
    "        norm5 = tf.nn.dropout(norm5, 1-dp)\n",
    "        ffn1 = tf.layers.separable_conv1d(norm5, 128, 1, activation=tf.nn.relu)\n",
    "        ffn1 = tf.nn.dropout(ffn1, 1-dp)\n",
    "        ffn2 = tf.layers.separable_conv1d(ffn1, 128, 1)\n",
    "        ffn2 = tf.nn.dropout(ffn2, 1-dp)\n",
    "        residual7 = tf.add(residual6, ffn2)\n",
    "    return residual7\n",
    "\n",
    "def model_encoder_block(scope, inputs, projection=False):\n",
    "    with tf.variable_scope(scope,reuse=tf.AUTO_REUSE):\n",
    "        inputs = position_encoding(inputs)\n",
    "        if projection:\n",
    "            outputs = tf.layers.separable_conv1d(inputs, 128, 1, padding=\"same\", activation=tf.nn.relu)\n",
    "        else:\n",
    "            outputs = inputs\n",
    "        for i in range(7):\n",
    "            with tf.variable_scope(\"conv_block{}\".format(i),reuse=tf.AUTO_REUSE):\n",
    "                norm0 = tf.contrib.layers.layer_norm(outputs)\n",
    "                norm0 = tf.nn.dropout(norm0, 1-dp)\n",
    "                conv0 = tf.layers.separable_conv1d(norm0, 128, 5, padding=\"same\", activation=tf.nn.relu)\n",
    "                conv0 = tf.nn.dropout(conv0, 1-dp)\n",
    "                residual0 = tf.add(outputs, conv0)\n",
    "                \n",
    "                norm1 = tf.contrib.layers.layer_norm(residual0)\n",
    "                norm1 = tf.nn.dropout(norm1, 1-dp)\n",
    "                conv1 = tf.layers.separable_conv1d(norm1, 128, 5, padding=\"same\", activation=tf.nn.relu)\n",
    "                conv1 = tf.nn.dropout(conv1, 1-dp)\n",
    "                residual1 = tf.add(residual0, conv1)\n",
    "            \n",
    "            with tf.variable_scope(\"self_attention{}\".format(i),reuse=tf.AUTO_REUSE):\n",
    "                norm2 = tf.contrib.layers.layer_norm(residual1)\n",
    "                norm2 = tf.nn.dropout(norm2, 1-dp)\n",
    "                attention_out = multihead_self_attention(norm2, \"self_attention\")\n",
    "                attention_out = tf.nn.dropout(attention_out, 1-dp)\n",
    "                residual2 = tf.add(residual1, attention_out)\n",
    "            \n",
    "            with tf.variable_scope(\"feedforward{}\".format(i),reuse=tf.AUTO_REUSE):\n",
    "                norm3 = tf.contrib.layers.layer_norm(residual2)\n",
    "                norm3 = tf.nn.dropout(norm3, 1-dp)\n",
    "                ffn1 = tf.layers.separable_conv1d(norm3, 128, 1, activation=tf.nn.relu)\n",
    "                ffn1 = tf.nn.dropout(ffn1, 1-dp)\n",
    "                ffn2 = tf.layers.separable_conv1d(ffn1, 128, 1)\n",
    "                ffn2 = tf.nn.dropout(ffn2, 1-dp)\n",
    "                outputs = tf.add(residual2, ffn2)\n",
    "    return outputs\n",
    "\n",
    "def highway(scope, inputs):\n",
    "    # two layer highway network\n",
    "    size = inputs.shape.as_list()[-1]\n",
    "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "        T1 = tf.layers.separable_conv1d(inputs, size, 1, activation=tf.nn.sigmoid, bias_initializer=tf.constant_initializer(-1))\n",
    "        H1 = tf.layers.separable_conv1d(inputs, size, 1, activation=tf.nn.relu)\n",
    "        H1 = tf.nn.dropout(H1, 1-dp)\n",
    "        highway1 = T1 * H1 + inputs * (1.0 - T1)\n",
    "        \n",
    "        T2 = tf.layers.separable_conv1d(highway1, size, 1, activation=tf.nn.sigmoid, bias_initializer=tf.constant_initializer(-1))\n",
    "        H2 = tf.layers.separable_conv1d(highway1, size, 1, activation=tf.nn.relu)\n",
    "        H2 = tf.nn.dropout(H2, 1-dp)\n",
    "        highway2 = T2 * H2 + highway1 * (1.0 - T2)\n",
    "    return highway2\n",
    "\n",
    "def multihead_self_attention(inputs, scope, heads=8):\n",
    "    # restricted multi-head self-attention\n",
    "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "        depth = inputs.get_shape().as_list()[-1]\n",
    "        WQ = tf.get_variable(\"WQ\", [depth, depth])\n",
    "        WK = tf.get_variable(\"WK\", [depth, depth])\n",
    "        WV = tf.get_variable(\"WV\", [depth, depth])\n",
    "        \n",
    "        Q = tf.einsum(\"bsd,dw->bsw\", inputs, WQ)\n",
    "        K = tf.einsum(\"bsd,dw->bsw\", inputs, WK)\n",
    "        V = tf.einsum(\"bsd,dw->bsw\", inputs, WV) # [batch, sequence_length, depth]\n",
    "        \n",
    "        # split shape for vectorization\n",
    "        Q_ = tf.concat(tf.split(Q, heads, axis=2), axis=0)\n",
    "        K_ = tf.concat(tf.split(K, heads, axis=2), axis=0)\n",
    "        V_ = tf.concat(tf.split(V, heads, axis=2), axis=0) # [8 * batch, sequence_length, depth / 8]\n",
    "        \n",
    "        attention_logits = tf.matmul(Q_, K_, transpose_b=True)\n",
    "        dk = depth / heads\n",
    "        scaled = tf.divide(attention_logits, tf.sqrt(dk))\n",
    "        attention = layer_softmax(scaled, axis=-1)\n",
    "        #attention = tf.nn.softmax(scaled, axis=-1)\n",
    "        attention_out = tf.matmul(attention, V_)\n",
    "        \n",
    "        # retrieve shape\n",
    "        attention_out = tf.concat(tf.split(attention_out, heads, axis=0), axis=2)\n",
    "    return attention_out\n",
    "\n",
    "def position_encoding(inputs):\n",
    "    \"\"\"\n",
    "    sinusoids position encoding\n",
    "    from One Model to Learn Then All\n",
    "    -- input: [None, sequence_length, depth]\n",
    "    -- output: [None, sequence_length, depth]\n",
    "    \"\"\"\n",
    "    _, seq_length, depth = inputs.get_shape().as_list()\n",
    "    pos_encoding = np.array([\n",
    "        [pos * np.power(1e-4, -(i//2)*2/depth) for i in range(depth)]\n",
    "        for pos in range(seq_length)])\n",
    "    pos_encoding[:, 0::2] = np.sin(pos_encoding[:, 0::2])\n",
    "    pos_encoding[:, 1::2] = np.cos(pos_encoding[:, 1::2])\n",
    "    pos_encoding = tf.convert_to_tensor(pos_encoding, tf.float32)\n",
    "    return inputs+pos_encoding\n",
    "\n",
    "def query_context_co_attention(w, inputs, context, query):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        w: similarity funciton weight\n",
    "        inputs: [q, c, q*c]\n",
    "    output:\n",
    "        A: context-to-query attention\n",
    "        B: query-to-context attention\n",
    "    \"\"\"\n",
    "    # similarity matrix S (logits)\n",
    "    S = tf.einsum(\"abcde,ef->abcdf\", tf.expand_dims(inputs,3),w)\n",
    "    S = tf.squeeze(S,[-2,-1])\n",
    "    \n",
    "    # S_: softmax over rows\n",
    "    S_ = layer_softmax(S)\n",
    "    #S_ = tf.nn.softmax(S)\n",
    "    \n",
    "    # S__T: transpose of softmax over coloum\n",
    "    S__T = tf.transpose(layer_softmax(S, axis=1),[0,2,1])\n",
    "    #S__T = tf.transpose(tf.nn.softmax(S, axis=1),[0,2,1])\n",
    "    \n",
    "    # context_query attention\n",
    "    A = tf.matmul(S_, query)\n",
    "    # query_context attention\n",
    "    B = tf.matmul(tf.matmul(S_, S__T), context)\n",
    "    return A, B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(filename)\n",
    "\n",
    "def parser(record):\n",
    "    keys_to_features = {\n",
    "        \"c\": tf.FixedLenSequenceFeature((), tf.int64, allow_missing=True),\n",
    "        \"c_char\": tf.FixedLenSequenceFeature((), tf.int64, allow_missing=True),\n",
    "        \"q\": tf.FixedLenSequenceFeature((), tf.int64, allow_missing=True),\n",
    "        \"q_char\": tf.FixedLenSequenceFeature((), tf.int64, allow_missing=True),\n",
    "        \"label\":tf.FixedLenFeature(shape=[], dtype=tf.int64)\n",
    "    }\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "    c = tf.cast(parsed[\"c\"], tf.int32)\n",
    "    c_char = tf.cast(parsed[\"c_char\"], tf.int32)\n",
    "    q = tf.cast(parsed[\"q\"], tf.int32)\n",
    "    q_char = tf.cast(parsed[\"q_char\"], tf.int32)\n",
    "    label = tf.cast(parsed[\"label\"], tf.int32)\n",
    "\n",
    "    return c, c_char, q, q_char, label\n",
    "\n",
    "def make_dataset(dataset):\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(10000, epoch))\n",
    "    dataset = dataset.batch(batch)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    return iterator\n",
    "\n",
    "train_iter = make_dataset(dataset)\n",
    "next_batch = train_iter.get_next()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    q_input = tf.placeholder(tf.int64, [None, 30], name=\"q\")\n",
    "    q_char_input = tf.placeholder(tf.int64, [None, 480], name=\"q_char\")\n",
    "    c_input = tf.placeholder(tf.int64, [None, 240], name=\"c\")\n",
    "    c_char_input = tf.placeholder(tf.int64, [None, 3840], name=\"c_char\")\n",
    "    \n",
    "    labels = tf.placeholder(tf.int64,[None],name=\"para_label\")\n",
    "    \n",
    "    start_mask = tf.placeholder(tf.int64, [None], name=\"start_mask\")\n",
    "    end_mask = tf.placeholder(tf.int64, [None], name=\"end_mask\")\n",
    "    \n",
    "    batch_size = tf.placeholder(tf.int64, (), name=\"batch_size\")\n",
    "    dp = tf.placeholder(tf.float32, (), name=\"drop_prob\")\n",
    "\n",
    "tf.add_to_collection(\"infer_input\", q_input)\n",
    "tf.add_to_collection(\"infer_input\", q_char_input)\n",
    "tf.add_to_collection(\"infer_input\", c_input)\n",
    "tf.add_to_collection(\"infer_input\", c_char_input)\n",
    "tf.add_to_collection(\"infer_input\", dp)\n",
    "\n",
    "with tf.variable_scope(\"Input_Embedding_Layer\"):\n",
    "    # input embedding layer\n",
    "    with tf.variable_scope(\"W_Embedding\"):\n",
    "        pretrained_embedding = tf.get_variable(\"w_embedding\",\n",
    "                                               shape=[72497,300],\n",
    "                                               initializer=tf.constant_initializer(embedding),\n",
    "                                               trainable=False)\n",
    "        unknown_embedding = tf.get_variable(\"unknown\",\n",
    "                                            shape=[1, 300],\n",
    "                                            initializer=tf.random_uniform_initializer(-0.5,0.5),\n",
    "                                            trainable=True)\n",
    "        tf.summary.histogram(\"unknown_word_embedding\", unknown_embedding)\n",
    "        padding_embedding = tf.get_variable(\"padding\",\n",
    "                                            shape=[1, 300],\n",
    "                                            initializer=tf.zeros_initializer(),\n",
    "                                            trainable=False)\n",
    "        word_embedding = tf.concat([pretrained_embedding, unknown_embedding, padding_embedding], 0)\n",
    "        \n",
    "        q_embed = tf.nn.embedding_lookup(word_embedding, q_input)\n",
    "        q_embed = tf.nn.dropout(q_embed, 1-dp)\n",
    "        c_embed = tf.nn.embedding_lookup(word_embedding, c_input)\n",
    "        c_embed = tf.nn.dropout(c_embed, 1-dp)\n",
    "\n",
    "    with tf.variable_scope(\"C_Embedding\"):\n",
    "        char_embedding = tf.get_variable(\"c_embedding\",\n",
    "                                         shape=[209, 200],\n",
    "                                         initializer=tf.random_uniform_initializer(-0.5,0.5),\n",
    "                                         trainable=True)\n",
    "        padding = tf.get_variable(\"padding\",\n",
    "                                  shape=[1, 200],\n",
    "                                  initializer=tf.zeros_initializer(),\n",
    "                                  trainable=False)\n",
    "        char_combined = tf.concat([char_embedding, padding], 0)\n",
    "        tf.summary.histogram(\"character_embedding\", char_combined)\n",
    "        q_char_embed = tf.nn.embedding_lookup(char_combined, q_char_input)\n",
    "        c_char_embed = tf.nn.embedding_lookup(char_combined, c_char_input)\n",
    "        \n",
    "        squeeze_to_word_q = tf.layers.max_pooling1d(q_char_embed, 16, 16)\n",
    "        squeeze_to_word_q = tf.nn.dropout(squeeze_to_word_q, 1-dp*0.5)\n",
    "        squeeze_to_word_c = tf.layers.max_pooling1d(c_char_embed, 16, 16)\n",
    "        squeeze_to_word_c = tf.nn.dropout(squeeze_to_word_c, 1-dp*0.5)\n",
    "        \n",
    "    with tf.variable_scope(\"embedding_output\"):\n",
    "        q_embed_out = tf.concat([q_embed, squeeze_to_word_q], 2)\n",
    "        c_embed_out = tf.concat([c_embed, squeeze_to_word_c], 2)\n",
    "        q_embed_out = highway(\"highway\", q_embed_out)\n",
    "        c_embed_out = highway(\"highway\", c_embed_out)\n",
    "\n",
    "with tf.variable_scope(\"Embedding_Encoder_Layer\"):\n",
    "    # embedding encoder layer\n",
    "    q_encoded = embedding_encoder_block(\"encoder_block\", q_embed_out)\n",
    "    c_encoded = embedding_encoder_block(\"encoder_block\", c_embed_out)\n",
    "    print(q_encoded.shape, c_encoded.shape)\n",
    "    \n",
    "with tf.variable_scope(\"Context_Query_Attention_Layer\"):\n",
    "    # context_query attention layer\n",
    "    # first compute similarity matrix between context and query\n",
    "    # S_tj = w * [C_t; Q_j; C_t*Q_j]\n",
    "    c_expand = tf.expand_dims(c_encoded, 2)\n",
    "    c_expand = tf.tile(c_expand, [1,1,30,1])\n",
    "    \n",
    "    q_expand = tf.expand_dims(q_encoded, 1)\n",
    "    q_expand = tf.tile(q_expand, [1,240,1,1])\n",
    "    \n",
    "    qc_mul = tf.multiply(c_expand, q_expand)\n",
    "    \n",
    "    qc_concat = tf.concat([c_expand,q_expand,qc_mul], 3)\n",
    "    w = tf.get_variable(\"s_w\", [384,1])\n",
    "    tf.summary.histogram(\"S_matrix_weight\", w)\n",
    "    \n",
    "    A, B = query_context_co_attention(w, qc_concat, c_encoded, q_encoded)\n",
    "    \n",
    "    # layer output\n",
    "    G = tf.concat([c_encoded, A, tf.multiply(c_encoded,A), tf.multiply(c_encoded,B)],2)\n",
    "    print(G.shape)\n",
    "\n",
    "with tf.variable_scope(\"Model_Encoder_Layer\"):\n",
    "    # model encoder layer\n",
    "    model_encoder1 = model_encoder_block(\"model_encoder\", G, projection=True)\n",
    "    model_encoder2 = model_encoder_block(\"model_encoder\", model_encoder1, projection=False)\n",
    "    model_encoder3 = model_encoder_block(\"model_encoder\", model_encoder2, projection=False)\n",
    "    \n",
    "    print(model_encoder1.shape,model_encoder2.shape,model_encoder3.shape)\n",
    "\n",
    "with tf.variable_scope(\"Output_Layer\"):\n",
    "    # output layer\n",
    "    # p1: start probability sequence\n",
    "    # p2: end probability sequence\n",
    "    p1_input = tf.concat([model_encoder1, model_encoder2],2)\n",
    "    p2_input = tf.concat([model_encoder2, model_encoder3],2)\n",
    "    \n",
    "    l_input = tf.concat([model_encoder1, model_encoder2, model_encoder3],2)\n",
    "    out_1 = tf.layers.separable_conv1d(l_input, 300, 1)\n",
    "    out_2 = tf.squeeze(tf.layers.separable_conv1d(l_input, 1, 1),-1)\n",
    "    out1 = tf.layers.dense(out_2,20,activation = tf.nn.relu)\n",
    "    out_prob = tf.layers.dense(out1,classes,activation = tf.nn.softmax)\n",
    "    out_labels = tf.argmax(out_prob,axis=1)\n",
    "    \n",
    "    print (out1.shape)\n",
    "    \n",
    "        \n",
    "tf.add_to_collection(\"labels\", out_labels)\n",
    "\n",
    "global_step = tf.Variable(0,dtype=tf.int64,trainable=False,name='global_step')\n",
    "    \n",
    "with tf.variable_scope(\"Optimizer\"):\n",
    "    \n",
    "    # add l2 weight decay to all variables\n",
    "    trainables = tf.trainable_variables()\n",
    "    loss_l2 = tf.add_n([ tf.nn.l2_loss(v) for v in trainables if 'bias' not in v.name ]) * 3e-7\n",
    "    tf.summary.histogram(\"l2_loss\", loss_l2)\n",
    "    \n",
    "    true_prob = tf.one_hot(labels,depth=classes)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=true_prob,logits=out_prob)) + loss_l2\n",
    "    print (out_prob.shape,true_prob.shape)\n",
    "    \n",
    "    # perform cold warm up and gradient clipping\n",
    "    lr = 1e-7\n",
    "    lr = tf.minimum(lr, lr / tf.log(999.) * tf.log(tf.cast(global_step, tf.float32) + 1))\n",
    "    optimizer = tf.train.AdamOptimizer(lr, beta1=0.8,epsilon=1e-7)\n",
    "    opt_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    # apply exponential moving average\n",
    "    # used in inference\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9999)\n",
    "    with tf.control_dependencies([opt_op]):\n",
    "        train_step = ema.apply(trainables)\n",
    "\n",
    "tf.add_to_collection(\"train_step\", train_step)\n",
    "        \n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "f_measure_train = tf.get_variable(\"f_train\", (), trainable=False)\n",
    "f_measure_dev = tf.get_variable(\"f_dev\", (), trainable=False)\n",
    "tf.summary.scalar(\"f_train\", f_measure_train)\n",
    "tf.summary.scalar(\"f_dev\", f_measure_dev)\n",
    "print(out_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with tf.device(\"/device:GPU:0\"):\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(train_iter.initializer)\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"log/\", sess.graph)\n",
    "saver = tf.train.Saver(max_to_keep=2000)\n",
    "gen = dev_batch()\n",
    "\n",
    "cnt = 0\n",
    "f_t = 0\n",
    "f_d = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "    try:\n",
    "\n",
    "        next_c, next_c_char, next_q, next_q_char, next_labels = sess.run(next_batch)\n",
    "        \n",
    "        feed_dict = {q_input: next_q,\n",
    "                     q_char_input: next_q_char,\n",
    "                     c_input: next_c,\n",
    "                     c_char_input: next_c_char,\n",
    "                     labels:next_labels,\n",
    "                     f_measure_train: f_t,\n",
    "                     f_measure_dev: f_d,\n",
    "                     batch_size: len(next_c),\n",
    "                     dp:0.5}\n",
    "\n",
    "        run_ops = [train_step, out_labels, global_step, merged]\n",
    "\n",
    "        if cnt % 5000 == 0:\n",
    "            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "            run_metadata = tf.RunMetadata()\n",
    "            _, pl, step, s = sess.run(run_ops, feed_dict=feed_dict, options=run_options, run_metadata=run_metadata)\n",
    "            writer.add_run_metadata(run_metadata, \"steps{}\".format(step), global_step=step)\n",
    "            writer.add_summary(s, step)\n",
    "            fetched_timeline = timeline.Timeline(run_metadata.step_stats)\n",
    "            chrome_trace = fetched_timeline.generate_chrome_trace_format()\n",
    "            with open('timeline/timeline{}.json'.format(step), 'w') as f:\n",
    "                f.write(chrome_trace)\n",
    "        else:\n",
    "            _, pl, step, s = sess.run(run_ops, feed_dict=feed_dict)\n",
    "            writer.add_summary(s, step)\n",
    "            \n",
    "        if cnt % 10 == 0:\n",
    "            f_t = (np.round(pl).astype(int)==next_labels).mean()\n",
    "\n",
    "        if cnt % 10 == 0:\n",
    "            c_d, c_char_d, q_d, q_char_d, dev_label = next(gen)\n",
    "            pl = sess.run(out_labels, feed_dict={q_input:q_d,\n",
    "                                                             q_char_input: q_char_d,\n",
    "                                                             c_input: c_d,\n",
    "                                                             c_char_input: c_char_d,\n",
    "                                                             labels:dev_label,\n",
    "                                                             dp: 0})\n",
    "            f_d = (np.round(pl).astype(int)==dev_label).mean()\n",
    "\n",
    "\n",
    "\n",
    "        if cnt % 5000 == 0:\n",
    "            print(cnt)\n",
    "            saver.save(sess, \"model2/strong\", global_step=step)\n",
    "\n",
    "        print (cnt,end = '\\r')\n",
    "        cnt += 1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        saver.save(sess, \"model1/strong\", global_step=step)\n",
    "print(\"done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
