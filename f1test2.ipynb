{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\NLP\\QA\\output\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "import pickle\n",
    "import math\n",
    "import spacy\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "%cd \"E:\\NLP\\QA\\output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"documents.json\") as f:\n",
    "    doc = json.load(f)\n",
    "with open(\"devel.json\") as f:\n",
    "    dev = json.load(f)\n",
    "with open(\"word_dict2.json\") as f:\n",
    "    word_dict = json.load(f)\n",
    "with open(\"char_dict2.json\") as f:\n",
    "    char_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding = np.load(\"embedding2.npy\").astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "stopword = set(stopwords.words('english'))\n",
    "punc = set(['\"','\\'',\"?\",\".\",\",\",\"/\",\"<\",\">\",\":\",\";\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrices loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3097/3097 [00:07<00:00, 433.31it/s]\n"
     ]
    }
   ],
   "source": [
    "def unknown_detection(token_list):\n",
    "    new_list = []\n",
    "    for token in token_list:\n",
    "        if token in word_dict:\n",
    "            new_list.append(token)\n",
    "        else:\n",
    "            new_list.append(\"<UNK>\")\n",
    "    return new_list\n",
    "\n",
    "def generate_char(token_list):\n",
    "    new_list = []\n",
    "    for token in token_list:\n",
    "        if token == \"<PAD>\":\n",
    "            char_list = [\"<pad>\"]*16\n",
    "        else:\n",
    "            char_list = [c for c in token[:16]]\n",
    "        while len(char_list) < 16:\n",
    "            char_list.append(\"<pad>\")\n",
    "        for char in char_list:\n",
    "            if char in char_dict:\n",
    "                new_list.append(char)\n",
    "            else:\n",
    "                new_list.append(\"<unk>\")\n",
    "    assert len(new_list) == len(token_list) * 16\n",
    "    return new_list\n",
    "\n",
    "if os.path.exists(\"tfidfs.pickle\"):\n",
    "    with open(\"tfidfs.pickle\",\"rb\") as f:\n",
    "        tfidfs = pickle.load(f)\n",
    "    tqdm.write(\"matrices loaded\")\n",
    "else:\n",
    "    tfidfs = dict()\n",
    "    for d in doc:\n",
    "        tfidf = TfidfVectorizer(tokenizer=word_tokenize,\n",
    "                                stop_words='english',\n",
    "                                max_df=0.5,\n",
    "                                smooth_idf=False,\n",
    "                                sublinear_tf=True)\n",
    "        paragraphs = [p.lower() for p in d[\"text\"]]\n",
    "        res = tfidf.fit_transform(paragraphs).toarray()\n",
    "        mapping = tfidf.vocabulary_\n",
    "        tfidfs[d[\"docid\"]] = [res, mapping]\n",
    "    with open(\"tfidfs.pickle\",\"wb\") as f:\n",
    "        pickle.dump(tfidfs, f)\n",
    "    tqdm.write(\"matrices building complete\")\n",
    "\n",
    "topk_p = 4\n",
    "topk_s = 6\n",
    "\n",
    "padded_dev = []\n",
    "for sample in tqdm(dev):\n",
    "    new_sample = dict()\n",
    "    \n",
    "    docid = sample[\"docid\"]\n",
    "    answer = word_tokenize(sample[\"text\"])\n",
    "\n",
    "    question = word_tokenize(sample[\"question\"].lower().strip())\n",
    "    rmed = []\n",
    "    for token in question:\n",
    "        if token not in stopword and token not in punc:\n",
    "            rmed.append(token)\n",
    "    question = rmed\n",
    "    \"\"\"\n",
    "    res, mapping = tfidfs[docid]\n",
    "    # set accumulator for each paragraph\n",
    "    a_d = [0 for _ in range(res.shape[0])]\n",
    "    for token in question:\n",
    "        for i in range(len(a_d)):\n",
    "            if token in mapping:\n",
    "                a_d[i] += res[i, mapping[token]]\n",
    "\n",
    "    k = topk_p if res.shape[0] > topk_p else res.shape[0]\n",
    "    pred = np.argpartition(a_d, -k)[-k:]\n",
    "    pred = set(pred)\n",
    "    combined = []\n",
    "    for idx in pred:\n",
    "        sents = [s.text for s in nlp(doc[docid][\"text\"][idx]).sents]\n",
    "        for s in sents:\n",
    "            combined.append(s.lower())\n",
    "\n",
    "    # rank sentences in combined sents\n",
    "    tfidf = TfidfVectorizer(smooth_idf=False,\n",
    "                            sublinear_tf=True,\n",
    "                            tokenizer=word_tokenize)\n",
    "    array = tfidf.fit_transform(combined).toarray()\n",
    "    mapping = tfidf.vocabulary_\n",
    "\n",
    "    a_d = np.zeros(len(combined))\n",
    "    for token in question:\n",
    "        for i in range(len(a_d)):\n",
    "            if token in mapping:\n",
    "                a_d[i] += array[i, mapping[token]]\n",
    "    # return top k results\n",
    "    k = topk_s if len(combined) > topk_s else len(combined)\n",
    "    pred = np.argpartition(a_d, -k)[-k:]\n",
    "    pred = pred[np.argsort(a_d[pred])].tolist()\n",
    "    \n",
    "    para = []\n",
    "    while len(para) < 240 and len(pred) > 0:\n",
    "        idx = pred.pop()\n",
    "        sent = word_tokenize(combined[idx])[:80]\n",
    "        l = len(sent)\n",
    "        if len(para) + l <= 240:\n",
    "            para += sent\n",
    "    \"\"\"\n",
    "    para = word_tokenize(doc[docid][\"text\"][sample[\"answer_paragraph\"]].lower())[:240]\n",
    "    \n",
    "    content_char = generate_char(para)\n",
    "    content = unknown_detection(para)\n",
    "        \n",
    "    padded_question = word_tokenize(sample[\"question\"].lower())[:30]\n",
    "    while len(padded_question) < 30:\n",
    "        padded_question.append(\"<PAD>\")\n",
    "    question_char = generate_char(padded_question)\n",
    "    padded_question = unknown_detection(padded_question)\n",
    "    \n",
    "    new_sample[\"question\"] = padded_question\n",
    "    new_sample[\"q_char\"] = question_char\n",
    "    new_sample[\"content\"] = content\n",
    "    new_sample[\"c_char\"] = content_char\n",
    "    new_sample[\"answer\"] = answer\n",
    "    new_sample[\"answer_idx\"] = 0\n",
    "    \n",
    "    assert len(padded_question) == 30\n",
    "    assert len(question_char) == 480\n",
    "    assert len(content) <= 240\n",
    "    assert len(content_char) <= 3840\n",
    "    assert len(content_char) == len(content) * 16\n",
    "    \n",
    "    padded_dev.append(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_input_data(padded):\n",
    "\n",
    "    c, c_chars, q, q_chars, a_idx, answer = [], [], [], [], [], []\n",
    "\n",
    "    for sample in tqdm(padded):\n",
    "        question = sample[\"question\"]\n",
    "        content = sample[\"content\"]\n",
    "        q_char = sample[\"q_char\"]\n",
    "        c_char = sample[\"c_char\"]\n",
    "        a = sample[\"answer\"]\n",
    "        aidx = sample[\"answer_idx\"]\n",
    "\n",
    "        q_mapped = [word_dict[t] for t in question]\n",
    "        c_mapped = [word_dict[t] for t in content]\n",
    "        q_char_mapped = [char_dict[ch] for ch in q_char]\n",
    "        c_char_mapped = [char_dict[ch] for ch in c_char]\n",
    "        \n",
    "        c_mapped = tf.keras.preprocessing.sequence.pad_sequences([c_mapped], maxlen=240, padding=\"post\",value=word_dict[\"<PAD>\"])[0]\n",
    "        c_char_mapped = tf.keras.preprocessing.sequence.pad_sequences([c_char_mapped], maxlen=3840, padding=\"post\",value=char_dict[\"<pad>\"])[0]\n",
    "        \n",
    "        c.append(c_mapped)\n",
    "        q.append(q_mapped)\n",
    "        c_chars.append(c_char_mapped)\n",
    "        q_chars.append(q_char_mapped)\n",
    "        answer.append(a)\n",
    "        a_idx.append(aidx)\n",
    "        \n",
    "    return np.array(c), np.array(c_chars), np.array(q), np.array(q_chars), np.array(a_idx), answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3097/3097 [00:01<00:00, 1900.10it/s]\n"
     ]
    }
   ],
   "source": [
    "c, c_char, q, q_char, _, answer = generate_input_data(padded_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3097, 240) (3097, 3840)\n",
      "(3097, 30) (3097, 480)\n",
      "3097\n"
     ]
    }
   ],
   "source": [
    "print(c.shape, c_char.shape)\n",
    "print(q.shape, q_char.shape)\n",
    "print(len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_indices = np.arange(len(c))\n",
    "def dev_batch(batch=16):\n",
    "    np.random.shuffle(train_indices)\n",
    "    for i in range(int(math.ceil(len(c)/batch))):\n",
    "        start_index = (i*batch)%len(c)\n",
    "        idx = train_indices[start_index:start_index+batch]\n",
    "        c_b = c[idx]\n",
    "        c_char_b = c_char[idx]\n",
    "        q_b = q[idx]\n",
    "        q_char_b = q_char[idx]\n",
    "        a_b = []\n",
    "        for j in idx:\n",
    "            a_b.append(answer[j])\n",
    "        yield c_b, c_char_b, q_b, q_char_b, a_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_dev(pred_s, pred_e, a, context):\n",
    "    # computes average f_measure for a batch\n",
    "    f_sum = 0\n",
    "    l = len(pred_s)\n",
    "    for i in range(l):\n",
    "        s_i = np.argmax(pred_s[i])\n",
    "        e_i = np.argmax(pred_e[i])\n",
    "        if e_i < s_i:\n",
    "            continue\n",
    "        TP, FN, FP = 0, 0, 0\n",
    "        guess = context[i][s_i:e_i+1]\n",
    "        true = [word_dict[t] for t in unknown_detection(a[i])]\n",
    "        for token in guess:\n",
    "            if token in true:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        for token in true:\n",
    "            if token not in guess:\n",
    "                FN += 1\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        f = 2*precision*recall/(precision+recall+1e-8)\n",
    "        f_sum += f\n",
    "    return f_sum/l\n",
    "\n",
    "def f_train(pred_s, pred_e, true_s, true_e, context):\n",
    "    # computes average f_measure for a batch\n",
    "    f_sum = 0\n",
    "    l = len(pred_s)\n",
    "    for i in range(l):\n",
    "        s_i = np.argmax(pred_s[i])\n",
    "        e_i = np.argmax(pred_e[i])\n",
    "        if e_i < s_i:\n",
    "            continue\n",
    "        TP, FN, FP = 0, 0, 0\n",
    "        guess = context[i][s_i:e_i+1]\n",
    "        true = context[i][true_s[i]:true_e[i]+1]\n",
    "        for token in guess:\n",
    "            if token in true:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        for token in true:\n",
    "            if token not in guess:\n",
    "                FN += 1\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        f = 2*precision*recall/(precision+recall+1e-8)\n",
    "        f_sum += f\n",
    "    return f_sum/l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_dp(set1,set2):\n",
    "    assert len(set1) == len(set2)\n",
    "    max1 = 0\n",
    "    maxi1 = 0\n",
    "    maxpair = None\n",
    "    maxp = 0\n",
    "    for i in range(len(set1)):\n",
    "        if set1[i]>max1:\n",
    "            max1 = set1[i]\n",
    "            maxi1 = i\n",
    "        if max1 * set2[i] > maxp:\n",
    "            maxp = max1 * set2[i]\n",
    "            maxpair = [maxi1,i]\n",
    "    assert maxpair[0] <= maxpair[1]\n",
    "    return maxpair,maxp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\\strong-21000\n",
      "0.28124999851562504\n",
      "0.2571022714102854\n",
      "0.22083333179583337\n",
      "0.29062499842890627\n",
      "0.44999999721249995\n",
      "0.1532738083149093\n",
      "0.3124999984375\n",
      "0.48055555300478403\n",
      "0.3820312476345704\n",
      "0.32193396061443125\n",
      "0.2916666649479167\n",
      "0.38541666459201385\n",
      "0.2708333318402778\n",
      "0.3283730139228238\n",
      "0.33749999792916663\n",
      "0.3374999981375\n",
      "0.2537202366603334\n",
      "0.5510416635042534\n",
      "0.22894736714072023\n",
      "0.149305554607446\n",
      "0.3124999984375\n",
      "0.36458333122395836\n",
      "0.48124999729999995\n",
      "0.45833333090277784\n",
      "0.3762310578206389\n",
      "0.3574999981117222\n",
      "0.34166666483888886\n",
      "0.32291666500868055\n",
      "0.3729166646045139\n",
      "0.2782738079210955\n",
      "0.44791666420138887\n",
      "0.522115381605991\n",
      "0.3589962100070256\n",
      "0.4166666644791666\n",
      "0.33286561033679246\n",
      "0.12711864318759428\n",
      "0.4145833309934027\n",
      "0.24999999854166666\n",
      "0.48749999723472226\n",
      "0.29013364592557456\n",
      "0.3104166649170139\n",
      "0.48749999751249995\n",
      "0.32384259049991426\n",
      "0.17708333223090278\n",
      "0.30160018385488374\n",
      "0.2708333318402778\n",
      "0.38503787639330356\n",
      "0.27499999845\n",
      "0.45231481231709536\n",
      "0.21874999875\n",
      "0.48749999720000003\n",
      "0.2704146712156121\n",
      "0.3570736415421812\n",
      "0.16586538366725223\n",
      "0.3333333315277778\n",
      "0.2395833315625\n",
      "0.3345238075429705\n",
      "0.21677735484159386\n",
      "0.5187499972\n",
      "0.24791666515138888\n",
      "0.15328282710629146\n",
      "0.4641598891114557\n",
      "0.43409267663100726\n",
      "0.27499999845\n",
      "0.4197510796187316\n",
      "0.2886217930127877\n",
      "0.19855072338227858\n",
      "0.48749999751249995\n",
      "0.20138888767168212\n",
      "0.3333333315277778\n",
      "0.49374999727812496\n",
      "0.3541666648263889\n",
      "0.4562499975125\n",
      "0.2874999980890306\n",
      "0.3613636342657025\n",
      "0.4999999974999999\n",
      "0.30180180018089037\n",
      "0.4216666643818888\n",
      "0.2999999983111111\n",
      "0.27708333143645836\n",
      "0.35208333122777774\n",
      "0.4562499975125\n",
      "0.5416666637326389\n",
      "0.3124999984375\n",
      "0.22346697991481068\n",
      "0.32083333133194447\n",
      "0.28124999851562504\n",
      "0.39583333121527775\n",
      "0.46666666411979163\n",
      "0.41666666401041663\n",
      "0.22589285564901504\n",
      "0.46360293855921275\n",
      "0.4687499973350694\n",
      "0.2854166648388889\n",
      "0.3694444421662424\n",
      "0.3517857121997449\n",
      "0.2556327145398325\n",
      "0.4002976166744614\n",
      "0.48124999693472215\n",
      "0.21741071310728635\n",
      "0.2916666648638889\n",
      "0.24776386453111823\n",
      "0.5022727244205522\n",
      "0.2770833315527778\n",
      "0.40416666452638894\n",
      "0.27592253012950363\n",
      "0.21874999882812501\n",
      "0.24826388723403744\n",
      "0.2705965892627491\n",
      "0.18057950060081424\n",
      "0.3201388865904321\n",
      "0.39374999790312504\n",
      "0.25101351192111265\n",
      "0.4270833309809028\n",
      "0.32341269660840266\n",
      "0.16666666557291668\n",
      "0.3791666645263889\n",
      "0.390624997890625\n",
      "0.3541666647916667\n",
      "0.5458333303402778\n",
      "0.4166666645138889\n",
      "0.3848684190867382\n",
      "0.2604166651388889\n",
      "0.5249999971999999\n",
      "0.10646024403552533\n",
      "0.30526373935434986\n",
      "0.26736110945987657\n",
      "0.23749999876250003\n",
      "0.2916666651388889\n",
      "0.2708333318402778\n",
      "0.11249999938750001\n",
      "0.3613821116511162\n",
      "0.39995184660144245\n",
      "0.4429347800875768\n",
      "0.5797619014276078\n",
      "0.3020833315277778\n",
      "0.3499999979666667\n",
      "0.10916666599366667\n",
      "0.2791666649951389\n",
      "0.424999997825\n",
      "0.3645833311711806\n",
      "0.48214285444727883\n",
      "0.2895833315506945\n",
      "0.45833333090277784\n",
      "0.46874999757812497\n",
      "0.2812499982291667\n",
      "0.4062499976041667\n",
      "0.20043103342932522\n",
      "0.22321428426232992\n",
      "0.43749999781249993\n",
      "0.5020833302333333\n",
      "0.34166666483888886\n",
      "0.3586309503636975\n",
      "0.24869791494479712\n",
      "0.37347461377853974\n",
      "0.33213562565114096\n",
      "0.40874999723244454\n",
      "0.41234755880823354\n",
      "0.38028375541196924\n",
      "0.2760578464318834\n",
      "0.13234126900100465\n",
      "0.30624999821562504\n",
      "0.2604166651388889\n",
      "0.206249998840625\n",
      "0.1928191477133672\n",
      "0.338026313937873\n",
      "0.19331395249543673\n",
      "0.21874999854166666\n",
      "0.19499999867262502\n",
      "0.2543103433015941\n",
      "0.31971153671089125\n",
      "0.2895833315402778\n",
      "0.23854166527092013\n",
      "0.45624999759062496\n",
      "0.3583333311583333\n",
      "0.4749999973166667\n",
      "0.2395833319813368\n",
      "0.37499999812499996\n",
      "0.23958333184895836\n",
      "0.149999999075\n",
      "0.21355164035668905\n",
      "0.2374999987625\n",
      "0.26874999845\n",
      "0.3416666648388889\n",
      "0.29999999845\n",
      "0.4761424705126044\n",
      "0.17499999907500002\n",
      "0.1575386588435607\n",
      "0.32083333147083337\n",
      "0.2166666652638889\n",
      "0.34166666460451395\n",
      "0.4354166642920139\n",
      "0.11249999938750001\n",
      "0.2514739215192304\n",
      "Done!\n",
      "0.32834743361566043\n"
     ]
    }
   ],
   "source": [
    "#tf.reset_default_graph()\n",
    "train = False\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    config = tf.ConfigProto(allow_soft_placement = True)\n",
    "    \n",
    "    with tf.Session(config=config) as sess:\n",
    "        variables_to_restore = ema.variables_to_restore()\n",
    "        ckpt = tf.train.get_checkpoint_state(os.path.dirname('./model/checkpoint'))\n",
    "        saver = tf.train.Saver(variables_to_restore)\n",
    "        gen = dev_batch()\n",
    "        #saver = tf.train.Saver()\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        if train:\n",
    "            sess.run(train_iter.initializer)\n",
    "\n",
    "        c_ph,c_char_ph, q_ph, q_char_ph, dp_in = tf.get_collection(\"infer_input\")\n",
    "        s_idx, e_idx = tf.get_collection(\"predictions\")\n",
    "        f_list = []\n",
    "        \n",
    "        i = 0\n",
    "        while True:\n",
    "            i += 1\n",
    "            if train:\n",
    "                next_c, next_c_char, next_q, next_q_char, next_mask = sess.run(next_batch)\n",
    "                next_smask = next_mask[:,0]\n",
    "                next_emask = next_mask[:,1]-1\n",
    "\n",
    "                feed_dict = {q_input: next_q,\n",
    "                             q_char_input: next_q_char,\n",
    "                             c_input: next_c,\n",
    "                             c_char_input: next_c_char,\n",
    "                             dp:0}\n",
    "            else:\n",
    "                \"\"\"\n",
    "                c_in = c[i:i+1,:]\n",
    "                c_char_in = c_char[i:i+1, :]\n",
    "                q_in = q[i:i+1, :]\n",
    "                q_char_in = q_char[i:i+1, :]\n",
    "                a_in = answer[i]\n",
    "                feed_dict={\"inputs/c:0\": c_in,\n",
    "                           \"inputs/c_char:0\": c_char_in,\n",
    "                           \"inputs/q:0\": q_in,\n",
    "                           \"inputs/q_char:0\": q_char_in,\n",
    "                           \"inputs/drop_prob:0\": 0.}\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    c_d, c_char_d, q_d, q_char_d, ans_d = next(gen)\n",
    "                except StopIteration:\n",
    "                    break\n",
    "                feed_dict={q_input:q_d,\n",
    "                             q_char_input: q_char_d,\n",
    "                             c_input: c_d,\n",
    "                             c_char_input: c_char_d,\n",
    "                             dp: 0}\n",
    "            \n",
    "            pred_s, pred_e = sess.run([s_idx, e_idx], feed_dict=feed_dict)\n",
    "            if train:\n",
    "                f = f_train(pred_s, pred_e, next_smask, next_emask, next_c)\n",
    "            else:\n",
    "                f = f_dev(pred_s, pred_e, ans_d, c_d)\n",
    "            print(f)\n",
    "            f_list.append(f)\n",
    "            if i % 200 == 0:\n",
    "                print(i)\n",
    "\n",
    "print(\"Done!\")\n",
    "print(sum(f_list)/len(f_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sum(f_list)/len(f_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
